{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement langcore-chains (from versions: none)\n",
      "ERROR: No matching distribution found for langcore-chains\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet neo4j langchain-community langchain-experimental langchain-openai json-repair langcore-chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Neo4j environment as the graph store -- comes with visualizations used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "neo_pass = os.getenv(\"NEO4J_PASS\")\n",
    "neo_db_id = os.getenv(\"DB_ID\")\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=\"neo4j+s://f5c81351.databases.neo4j.io\",\n",
    "    username=\"neo4j\",\n",
    "    password=neo_pass,\n",
    "    refresh_schema=False\n",
    ")\n",
    "\n",
    "def clean_graph():\n",
    "    query = \"\"\"\n",
    "    MATCH (n)\n",
    "    DETACH DELETE n\n",
    "    \"\"\"\n",
    "    graph.query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean graph if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to model (OpenAI for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[api_key] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain LLM Graph Transformer\n",
    "Establish connection with GPT 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test GraphRAG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Apples', type='Object', properties={}), Node(id='Small', type='Object', properties={})]\n",
      "Relationships:[Relationship(source=Node(id='Apples', type='Object', properties={}), target=Node(id='Small', type='Object', properties={}), type='SIZE', properties={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "with open('apple2.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "documents = [Document(page_content=text)]\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "\n",
    "\n",
    "\n",
    "# assign a unique document ID\n",
    "document_id = 'apple2'\n",
    "for graph_document in graph_documents:\n",
    "    # For nodes\n",
    "    for node in graph_document.nodes:\n",
    "        # Prepare Cypher query to add document_id to the node\n",
    "        query = \"\"\"\n",
    "        MATCH (n)\n",
    "        SET n.document_id = 'apple2'\n",
    "        RETURN n\n",
    "        \"\"\"\n",
    "        # Use graph.query() to run the query\n",
    "        graph.query(query, {\"node_id\": node.id, \"document_id\": document_id})\n",
    "\n",
    "\n",
    "\n",
    "no_schema = LLMGraphTransformer(llm=llm)\n",
    "data = await no_schema.aconvert_to_graph_documents(documents)\n",
    "graph.add_graph_documents(data)\n",
    "\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphQAChain chain...\u001b[0m\n",
      "Entities Extracted:\n",
      "\u001b[32;1m\u001b[1;3mApples\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "- Apples are a type of fruit\n",
      "- Apples are typically red, green, or yellow in color\n",
      "- Apples are a good source of fiber and vitamin C\n",
      "\n",
      "I'm sorry, I don't know the answer to your question.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import GraphQAChain\n",
    "\n",
    "# Assuming you have a properly populated graph and a language model (llm)\n",
    "chain = GraphQAChain.from_llm(\n",
    "    llm=llm, \n",
    "    graph=graph, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "question = \"What are the properties of Apples?\"\n",
    "response = chain.run(question)\n",
    "\n",
    "print(response)  # Check the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Nodes and Relationships using LangChain (specific nodes/relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Marie Curie', type='Person', properties={}), Node(id='1867', type='Year', properties={}), Node(id='Polish', type='Nationality', properties={}), Node(id='French', type='Nationality', properties={}), Node(id='Physicist', type='Scientist', properties={}), Node(id='Chemist', type='Scientist', properties={}), Node(id='Radioactivity', type='Research topic', properties={}), Node(id='Nobel Prize', type='Award', properties={}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='University Of Paris', type='University', properties={})]\n",
      "Relationships:[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='1867', type='Year', properties={}), type='BORN_IN', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Polish', type='Nationality', properties={}), type='NATIONALITY', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='French', type='Nationality', properties={}), type='NATIONALITY', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Physicist', type='Scientist', properties={}), type='PROFESSION', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Chemist', type='Scientist', properties={}), type='PROFESSION', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Radioactivity', type='Research topic', properties={}), type='RESEARCH_ON', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='AWARDEE', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Nobel Prize', type='Award', properties={}), type='AWARDEE', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Pierre Curie', type='Person', properties={}), type='MARRIED_TO', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University Of Paris', type='University', properties={}), type='BECAME_PROFESSOR', properties={})]\n"
     ]
    }
   ],
   "source": [
    "llm_transformer_props = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
    "    allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
    "    node_properties=[\"born_year\"],\n",
    ")\n",
    "graph_documents_props = llm_transformer_props.convert_to_graph_documents(documents)\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Properties to Graph Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph_documents_props' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m graph\u001b[38;5;241m.\u001b[39madd_graph_documents(\u001b[43mgraph_documents_props\u001b[49m, baseEntityLabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# baseEntityLabel allows us to optimize data retrieval even though we don't know all node labels and don't keep track of indices\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'graph_documents_props' is not defined"
     ]
    }
   ],
   "source": [
    "graph.add_graph_documents(graph_documents_props, baseEntityLabel=True)\n",
    "# baseEntityLabel allows us to optimize data retrieval even though we don't know all node labels and don't keep track of indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Send to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "no_schema = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = await no_schema.aconvert_to_graph_documents(documents)\n",
    "graph.add_graph_documents(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Graph with Neo4j browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import webbrowser\n",
    "webbrowser.open(f'https://{neo_db_id}.databases.neo4j.io/browser/', new=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Neo4j browser, use\n",
    "MATCH(n) return n\n",
    "to display graph (Cypher query language)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
